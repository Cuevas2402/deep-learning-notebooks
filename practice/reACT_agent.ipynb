{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models, have gained significant attention in recent years due to their importance in various applications. Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Speed and Scalability**: Fast language models can process large amounts of text data much faster than traditional models, making them ideal for applications that require real-time processing, such as chatbots, virtual assistants, and natural language processing (NLP) tasks.\n",
      "2. **Resource Efficiency**: Fast language models require fewer computational resources (e.g., memory, CPU) compared to traditional models, making them suitable for resource-constrained environments, such as mobile devices or embedded systems.\n",
      "3. **Latency Reduction**: Fast language models can significantly reduce the latency associated with processing and generating text, which is critical for applications that require instant responses, such as language translation, sentiment analysis, or text summarization.\n",
      "4. **Improved Search and Retrieval**: Fast language models can quickly index and search large text databases, enabling faster and more accurate retrieval of relevant information, which is essential for search engines, recommender systems, and other information retrieval applications.\n",
      "5. **Enhanced User Experience**: Fast language models can provide faster and more accurate responses to user queries, leading to a better user experience in applications like customer support chatbots, language translation services, or text-based interfaces.\n",
      "6. **Cost-Effective**: Fast language models can reduce the computational costs associated with processing and generating text, making them more cost-effective for organizations and individuals that require large-scale NLP processing.\n",
      "7. **Accelerating Research and Development**: Fast language models can accelerate research and development in NLP, enabling scientists to explore more complex models, experiment with new ideas, and achieve faster results, which can lead to breakthroughs in various fields.\n",
      "8. **Advancing Applications**: Fast language models have the potential to advance various applications, such as:\n",
      "\t* Language translation and localization\n",
      "\t* Sentiment analysis and opinion mining\n",
      "\t* Named entity recognition and information extraction\n",
      "\t* Text summarization and generation\n",
      "\t* Conversational AI and dialogue systems\n",
      "\t* Automated writing and content generation\n",
      "9. **Neural Network Pruning and Quantization**: Fast language models can be used to develop more efficient neural networks by pruning and quantizing the models, which can reduce their size and computational requirements.\n",
      "10. **Future-proofing**: As the amount of text data continues to grow, fast language models will be essential for processing and generating text at scale, ensuring that applications can keep up with the increasing demands of data processing and analysis.\n",
      "\n",
      "In summary, fast language models are crucial for applications that require fast and efficient processing of large amounts of text data, ensuring improved user experience, reduced costs, and accelerated research and development in NLP.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\tdef __init__(self, client, system):\n",
    "\t\tself.client = client\n",
    "\t\tself.system = system\n",
    "\t\tself.messages = []\n",
    "\t\tif self.system is not None:\n",
    "\t\t\tself.messages.append({\"role\": \"system\", \"content\" : self.system})\n",
    "\tdef __call__(self, message):\n",
    "\t\tif message:\n",
    "\t\t\tself.message.append({\"role\":\"user\", \"content\": message})\n",
    "\t\tresult = self.execute()\n",
    "\t\tself.meesage.append({\"role\":\"system\", \"content\": result})\n",
    "\t\treturn result\n",
    "\n",
    "\tdef execute(self):\n",
    "\t\tcompletion = client.chat.completions.create(\n",
    "\t\t\tmessages=self.messages,\n",
    "\t\t\tmodel=\"llama3-8b-8192\"\n",
    "\t\t)\n",
    "\t\treturn completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
